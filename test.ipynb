{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "!pip install torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 torchtext==0.18.0 torchdata==0.8.0 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install xformers==0.0.27\n",
    "\n",
    "!git clone --recursive https://github.com/theroyallab/tabbyAPI\n",
    "\n",
    "!apt update && apt install aria2 -y\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/config.json -d /content/tabbyAPI/models/llama3s -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/generation_config.json -d /content/tabbyAPI/models/llama3s -o generation_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/loss_log.txt -d /content/tabbyAPI/models/llama3s -o loss_log.txt\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/model.safetensors.index.json -d /content/tabbyAPI/models/llama3s -o model.safetensors.index.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/resolve/main/output.safetensors -d /content/tabbyAPI/models/llama3s -o output.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/special_tokens_map.json -d /content/tabbyAPI/models/llama3s -o special_tokens_map.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/tokenizer.json -d /content/tabbyAPI/models/llama3s -o tokenizer.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/tokenizer_config.json -d /content/tabbyAPI/models/llama3s -o tokenizer_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/janhq/llama3-s-instruct-v0.3-checkpoint-7000-phase-3-exllama2/raw/main/training_config_phase3.yaml -d /content/tabbyAPI/models/llama3s -o training_config_phase3.yaml\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://raw.githubusercontent.com/camenduru/ichigo-tost/refs/heads/main/tabbyAPI.yml -d /content/tabbyAPI -o config.yml\n",
    "\n",
    "!pip install https://github.com/turboderp/exllamav2/releases/download/v0.2.3/exllamav2-0.2.3+cu121.torch2.3.1-cp310-cp310-linux_x86_64.whl\n",
    "!pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl\n",
    "!pip install https://github.com/camenduru/wheels/releases/download/runpod/tabbyAPI-0.0.1-py3-none-any.whl\n",
    "\n",
    "%cd /content/tabbyAPI\n",
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone --recursive https://github.com/fishaudio/fish-speech\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/fishaudio/fish-speech-1.4/raw/main/config.json -d /content/fish-speech/checkpoints/fish-speech-1.4 -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/fishaudio/fish-speech-1.4/resolve/main/firefly-gan-vq-fsq-8x1024-21hz-generator.pth -d /content/fish-speech/checkpoints/fish-speech-1.4 -o firefly-gan-vq-fsq-8x1024-21hz-generator.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/fishaudio/fish-speech-1.4/resolve/main/model.pth -d /content/fish-speech/checkpoints/fish-speech-1.4 -o model.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/fishaudio/fish-speech-1.4/raw/main/special_tokens_map.json -d /content/fish-speech/checkpoints/fish-speech-1.4 -o special_tokens_map.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/fishaudio/fish-speech-1.4/raw/main/tokenizer.json -d /content/fish-speech/checkpoints/fish-speech-1.4 -o tokenizer.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/fishaudio/fish-speech-1.4/raw/main/tokenizer_config.json -d /content/fish-speech/checkpoints/fish-speech-1.4 -o tokenizer_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://raw.githubusercontent.com/camenduru/ichigo-tost/refs/heads/main/fishSpeechAPI.py -d /content/fish-speech/tools -o api.py\n",
    "\n",
    "!pip install https://github.com/camenduru/wheels/releases/download/runpod/fish_speech-0.1.0-py3-none-any.whl\n",
    "%cd /content/fish-speech/tools\n",
    "!uvicorn 'api:app' --workers 3 --host 0.0.0.0 --port 22311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!pip install whisperspeech matplotlib openai-whisper==20231117\n",
    "!pip install git+https://github.com/homebrewltd/WhisperSpeech.git\n",
    "!pip install vector_quantize_pytorch bitsandbytes transformers accelerate webdataset\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://raw.githubusercontent.com/camenduru/ichigo-tost/refs/heads/main/whisperAPI.py -d /content -o whisperAPI.py\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/jan-hq/WhisperVQ/resolve/main/whisper-vq-stoks-v3-7lang-fixed.model -d /content -o whisper-vq-stoks-v3-7lang-fixed.model\n",
    "!python whisperAPI.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone -b docker --recursive https://github.com/homebrewltd/ichigo-demo\n",
    "\n",
    "curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n",
    "export NVM_DIR=\"$HOME/.nvm\"\n",
    "[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" \n",
    "nvm install 18.20.3\n",
    "\n",
    "cd /content/ichigo-demo\n",
    "npm install\n",
    "npm run build\n",
    "npm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%env OPENAI_BASE_URL=http://localhost:5000/v1/\n",
    "%env TOKENIZE_BASE_URL=http://localhost:3348\n",
    "%env TTS_BASE_URL=http://localhost:22311/v1/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
